\relax 
\citation{Cummins09,Knopp2010,Schindler07}
\citation{Cummins09,Knopp2010,Schindler07}
\citation{Nister06,Philbin07,Sivic2003}
\citation{Csurka04,Sivic2003}
\citation{Bay06}
\citation{Lowe04}
\citation{Sivic2003}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  The goal of this work is to localize a query photograph (left) by finding other images of the same place in a large geotagged image database (right). We cast the problem as a classification task and learn a classifier for each location in the database. We develop a non-parametric \leavevmode {\color  {myGrey}(can we asy tis for FV e-svm norm?)} procedure to calibrate the outputs of the large number of per-location classifiers without the need for additional positive training data. \relax }}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{intro}{{1}{1}}
\citation{Mikulik2010,Philbin10b}
\citation{Jegou2011,Philbin08}
\citation{Chum11,Chum07b}
\citation{Irschara2009,Li10,Li12}
\citation{Philbin10c,Turcot09}
\citation{Torii11}
\citation{Knopp2010,Schindler07}
\citation{Zamir10}
\citation{Li09}
\citation{Malisiewicz11}
\citation{Malisiewicz11}
\citation{Malisiewicz11}
\citation{Knopp2010}
\@writefile{toc}{\contentsline {section}{\numberline {2}Per-location classifiers for place recognition}{2}}
\newlabel{sec:classifiers}{{2}{2}}
\newlabel{eq:class}{{1}{2}}
\@writefile{toc}{\contentsline {paragraph}{Learning per-location SVM classifiers. }{2}}
\newlabel{eq:linear}{{2}{2}}
\citation{Malisiewicz11}
\citation{Philbin07}
\citation{gebel2007calibrating}
\citation{Platt99}
\citation{zadrozny2002transforming}
\newlabel{eq:obj}{{3}{3}}
\@writefile{toc}{\contentsline {paragraph}{Expanding the positive set.}{3}}
\@writefile{toc}{\contentsline {paragraph}{Dual representation.}{3}}
\newlabel{eq:dual}{{4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Non-parametric calibration of the SVM-scores from negative examples only}{3}}
\newlabel{sec:calibration}{{3}{3}}
\citation{casella2001statistical}
\@writefile{toc}{\contentsline {paragraph}{Calibration \emph  {via} significance levels.}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:subfig1}{{2(a)}{4}}
\newlabel{sub@fig:subfig1}{{(a)}{4}}
\newlabel{fig:subfig2}{{2(b)}{4}}
\newlabel{sub@fig:subfig2}{{(b)}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{4}}
\newlabel{fig:calib}{{2}{4}}
\@writefile{toc}{\contentsline {paragraph}{Summary of the calibration procedure.}{4}}
\citation{Sivic2003}
\citation{Bay06}
\citation{Philbin07}
\citation{libsvm}
\citation{Chen11}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Affine calibration by re-normalization}{5}}
\newlabel{sec:calibrationRenorm}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{5}}
\newlabel{sec:experiments}{{5}{5}}
\@writefile{toc}{\contentsline {paragraph}{Implementation details.}{5}}
\@writefile{toc}{\contentsline {paragraph}{Image dataset.}{5}}
\citation{Malisiewicz11}
\citation{Philbin07}
\citation{Knopp2010}
\citation{Philbin07}
\citation{Knopp2010}
\citation{Philbin07}
\citation{Knopp2010}
\citation{Jegou12}
\citation{Knopp2010}
\citation{Knopp2010}
\citation{Malisiewicz11}
\bibstyle{spmpsci}
\bibdata{shortstrings,vggroup,cvww_template,mybib}
\bibcite{Bay06}{1}
\bibcite{casella2001statistical}{2}
\bibcite{Chen11}{3}
\bibcite{Chum11}{4}
\bibcite{Chum07b}{5}
\bibcite{Csurka04}{6}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  The percentage of correctly localized test queries for which the top-ranked database image is within $20$ meters from the ground truth query position. The proposed method (SVM p-val) outperforms the baseline methods. Results are shown for the initial retrieval (left column) and after re-ranking the top 20 retrieved images using geometric verification. Notice that SVM output without calibration gives $0\%$ of correctly localized queries. \relax }}{6}}
\newlabel{tab:eval}{{1}{6}}
\@writefile{toc}{\contentsline {paragraph}{Results.}{6}}
\@writefile{toc}{\contentsline {paragraph}{Scalability.}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{6}}
\bibcite{Cummins09}{7}
\bibcite{libsvm}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  {\bf  Examples of query images (gray) correctly (green) and incorrectly (red) localized by different methods.} \tmspace  +\thickmuskip {.2777em}(a) query image. \tmspace  +\thickmuskip {.2777em}(b) the top-ranked image retrieved by per-location classifiers (proposed method). \tmspace  +\thickmuskip {.2777em}(c) the top-ranked image retrieved by the baseline confuser suppression method\nobreakspace  {}\cite  {Knopp2010}. \tmspace  +\thickmuskip {.2777em}(d) the top-ranked image retrieved by the baseline bag-of-visual-words method. Bottom two rows: the proposed method is sometimes confused by high-scoring similar repeated texture patterns on facades. \relax }}{7}}
\newlabel{fig:demo1}{{3}{7}}
\bibcite{gebel2007calibrating}{9}
\bibcite{Irschara2009}{10}
\bibcite{Jegou2011}{11}
\bibcite{Jegou12}{12}
\bibcite{Knopp2010}{13}
\bibcite{Li09}{14}
\bibcite{Li10}{15}
\bibcite{Li12}{16}
\bibcite{Lowe04}{17}
\bibcite{Malisiewicz11}{18}
\bibcite{Mikulik2010}{19}
\bibcite{Nister06}{20}
\bibcite{Philbin07}{21}
\bibcite{Philbin08}{22}
\bibcite{Philbin10b}{23}
\bibcite{Philbin10c}{24}
\bibcite{Platt99}{25}
\bibcite{Schindler07}{26}
\bibcite{Sivic2003}{27}
\bibcite{Torii11}{28}
\bibcite{Turcot09}{29}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  {\bf  A visualization of learnt feature wights for two database images. In each panel:} \emph  {first\nobreakspace  {}row:} (Right) Target database image $j$. (Left) Cumulative density function (or calibrated score) learnt for the SVM scores of the corresponding classifier $f_j$; three query images displayed on the \emph  {second row} are represented by their SVM scores and cdf values $F_0(s)$, denoted (a)-(c) on the graph. \emph  {Third\nobreakspace  {}row:} A visualization of the contribution of each feature to the SVM score for the corresponding query image. Red circles represent features with negative weights while green circles correspond to features with positive weights. The area of each circle is proportional to the contribution of the corresponding feature to the SVM score. \par Notice that the correctly localized queries (c) contain more green colored features than queries from other places (b) and (a). {\it  Left panel:} Query (b) gets a high score because the building has orange and white stripes similar to the the sun-blinds of the bakery, which are features that also have large positive weights in the query image (c) of the correct place. {\it  Right panel:} Query (b) is in fact also an image of the same location with a portion of the left skyscraper in the target image detected in the upper left corner and the side of the rightmost building in the target image detected in the top right corner. Both are clearly detected by the method as indicated by a large quantity of green circles in the corresponding regions. \relax }}{8}}
\newlabel{fig:3qVSw}{{4}{8}}
\bibcite{zadrozny2002transforming}{30}
\bibcite{Zamir10}{31}
